{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0394112",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Trained on Graph Representations of Molecules for Predicting Toxicity\n",
    "\n",
    "(with stratified k-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c235a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 14:36:53.956267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pysmiles import read_smiles\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ca1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first obtain a list of smiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e56543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = pandas.read_csv(\"data/rdkit_descriptors.csv\") # load in rdkit descriptors from file\n",
    "desp_array = np.array(descriptors)\n",
    "x_smiles = list(desp_array[:,1]) # isolate smiles of 554 molecules from the rray of rdkit descriptors\n",
    "# x_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c90c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then convert them to Graphs - represented as adjacency matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f56f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_graph(smiles: str) -> nx.Graph:\n",
    "    # First, use the RDKit library to parse the SMILES string into a molecular graph\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Next, convert the RDKit molecular graph into a NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    for i in range(mol.GetNumAtoms()):\n",
    "        # Add the atomic number and explicit valence as attributes to the node\n",
    "        G.add_node(i, atomic_num=mol.GetAtomWithIdx(i).GetAtomicNum(),\n",
    "                      explicit_valence=mol.GetAtomWithIdx(i).GetExplicitValence())\n",
    "        \n",
    "    for i in range(mol.GetNumBonds()):\n",
    "        # Add the bond type as an attribute to the edge\n",
    "        G.add_edge(mol.GetBondWithIdx(i).GetBeginAtomIdx(),\n",
    "                   mol.GetBondWithIdx(i).GetEndAtomIdx(),\n",
    "                   bond_type=mol.GetBondWithIdx(i).GetBondType())\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82772b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_graphs = []\n",
    "for smile in x_smiles:\n",
    "    graph = smiles_to_graph(smile)\n",
    "    x_graphs.append(graph)\n",
    "# x_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32bb279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the y data - binarized toxicity labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fcf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pandas.read_csv(\"data/fathead_minnow_dataset.csv\")\n",
    "lc50 = original[\"LC50_(mg/L)\"]\n",
    "\n",
    "lc50_binary_list = []\n",
    "for value in lc50:\n",
    "    if value > 0.5:\n",
    "        lc50_binary_list.append(0) # not high toxicity\n",
    "    elif value <= 0.5:\n",
    "        lc50_binary_list.append(1)\n",
    "\n",
    "y = np.array(lc50_binary_list)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0f4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to then process the data as the matrices are all different shapes - pad smaller matrices with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d579bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(graphs):\n",
    "    # Convert each NetworkX graph into a NumPy array\n",
    "    adjacency_matrices = [nx.to_numpy_array(G) for G in graphs]\n",
    "\n",
    "    # Find the maximum shape of the adjacency matrices\n",
    "    max_shape = max([matrix.shape for matrix in adjacency_matrices])\n",
    "\n",
    "    # Pad the smaller matrices with zeros to make them the same shape as the largest matrix\n",
    "    padded_matrices = [np.pad(matrix, pad_width=[(0, max_shape[0] - matrix.shape[0]), (0, max_shape[1] - matrix.shape[1])], mode='constant', constant_values=0) for matrix in adjacency_matrices]\n",
    "\n",
    "    # Stack the padded arrays into a single 3D tensor\n",
    "    adjacency_matrix = np.stack(padded_matrices, axis=0)\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab89604",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_processed = preprocess_data(x_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5ab39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 33, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain shape of the x data\n",
    "x_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c796cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.99%\n",
      "accuracy: 92.79%\n",
      "accuracy: 93.69%\n",
      "accuracy: 90.09%\n",
      "accuracy: 92.73%\n",
      "92.06% (+/- 1.32%)\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "\n",
    "seed = 42 # manually set the seed value as it is needed for the kfold set up\n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(seed)  \n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed) # sets up the k-fold, n_splits = 5 so its 5-fold cross validation\n",
    "cvscores = [] # to record accuracy scores from each run\n",
    "\n",
    "X = x_processed # name your x dataset \"X\"\n",
    "\n",
    "for train, test in kfold.split((tf.expand_dims(X, axis=-1)), y): # this loop sets a new test/train split for each iteration in the loop\n",
    "    \n",
    "    model_cnn = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, 7, activation = 'relu', padding = 'same',\n",
    "                            input_shape = [33,33,1]),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same'),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same'),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation = 'relu'),\n",
    "        keras.layers.Dense(64, activation = 'relu'),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    model_cnn.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'nadam',\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    model_cnn.fit(X[train], y[train], epochs=30, verbose=0)\n",
    "    \n",
    "    # these lines here record all the scores\n",
    "    scores = model_cnn.evaluate(X[test], y[test], verbose=0) \n",
    "    print(\"%s: %.2f%%\" % (model_cnn.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4911fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
